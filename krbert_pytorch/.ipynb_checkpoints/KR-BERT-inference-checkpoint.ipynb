{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2386,
     "status": "ok",
     "timestamp": 1661397064469,
     "user": {
      "displayName": "­전해주 / 학생 / 컴퓨터공학부",
      "userId": "05510950798256053380"
     },
     "user_tz": -540
    },
    "id": "oudgx27cfXtp"
   },
   "outputs": [],
   "source": [
    "## import packages\n",
    "\n",
    "import torch\n",
    "from transformers import BertConfig, BertModel, BertForPreTraining, BertTokenizer\n",
    "from unicodedata import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1661397065723,
     "user": {
      "displayName": "­전해주 / 학생 / 컴퓨터공학부",
      "userId": "05510950798256053380"
     },
     "user_tz": -540
    },
    "id": "co_G4o8yeyW_",
    "outputId": "9674eb6f-6e66-41e8-9d96-b06d38bca9dc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1678: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## tokenizing preprocessing\n",
    "tokenizer_subchar = BertTokenizer.from_pretrained('pretrained/vocab_snu_subchar12367.txt', do_lower_case=False)\n",
    "tokenizer_char = BertTokenizer.from_pretrained('pretrained/vocab_snu_char16424.txt', do_lower_case=False)\n",
    "\n",
    "# convert a string into sub-char\n",
    "def to_subchar(string):\n",
    "    return normalize('NFKD', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1661397065724,
     "user": {
      "displayName": "­전해주 / 학생 / 컴퓨터공학부",
      "userId": "05510950798256053380"
     },
     "user_tz": -540
    },
    "id": "Wya5wf5VgmtH",
    "outputId": "81194b21-f6ca-4c95-8af0-43545ad3cbd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subchar:  ['데이터', '처리', '##를', '위한', '문자', '##열', '예', '##시', '##입니다', '.', '배', '##ᆺ', '##사람', '.', '추', '##ᆸ다', '.']\n",
      "   char:  ['데이터', '처리', '##를', '위한', '문자', '##열', '예', '##시', '##입니다', '.', '뱃', '##사람', '.', '춥', '##다', '.']\n"
     ]
    }
   ],
   "source": [
    "sentence = '데이터 처리를 위한 문자열 예시입니다. 뱃사람. 춥다.'\n",
    "\n",
    "print(\"subchar: \", tokenizer_subchar.tokenize(to_subchar(sentence)))\n",
    "print(\"   char: \", tokenizer_char.tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xxBpnJMkgm_H"
   },
   "outputs": [],
   "source": [
    "## Downstream tasks (Naver Sentiment Movie Corpus)\n",
    "## Based on 'KR-BERT character Bidirectional WordPiece'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B21SoDvFrJ18"
   },
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 4724,
     "status": "ok",
     "timestamp": 1661397070445,
     "user": {
      "displayName": "­전해주 / 학생 / 컴퓨터공학부",
      "userId": "05510950798256053380"
     },
     "user_tz": -540
    },
    "id": "uOaJt8EvSg8l"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpretrained\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenization_ranked\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FullTokenizer \u001b[38;5;28;01mas\u001b[39;00m KBertRankedTokenizer\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, BertConfig\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceClassifier\n",
      "File \u001b[0;32m~/Documents/GitHub/KR-BERT/krbert_pytorch/pretrained/tokenization_ranked.py:27\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01municodedata\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_case_matches_checkpoint\u001b[39m(do_lower_case, init_checkpoint):\n\u001b[1;32m     31\u001b[0m   \u001b[38;5;124;03m\"\"\"Checks whether the casing config is consistent with the checkpoint name.\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import pickle\n",
    "import json\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from pretrained.tokenization_ranked import FullTokenizer as KBertRankedTokenizer\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from model.net import SentenceClassifier\n",
    "from model.data import Corpus\n",
    "from model.utils import PreProcessor, PadSequence\n",
    "from model.metric import evaluate, acc\n",
    "from utils import Config, CheckpointManager, SummaryManager\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1661397070446,
     "user": {
      "displayName": "­전해주 / 학생 / 컴퓨터공학부",
      "userId": "05510950798256053380"
     },
     "user_tz": -540
    },
    "id": "I0eWvlhmSjpR"
   },
   "outputs": [],
   "source": [
    "# set path\n",
    "\n",
    "ptr_dir = Path('pretrained')\n",
    "data_dir = Path('data')\n",
    "model_dir = Path('checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1994,
     "status": "ok",
     "timestamp": 1661397072437,
     "user": {
      "displayName": "­전해주 / 학생 / 컴퓨터공학부",
      "userId": "05510950798256053380"
     },
     "user_tz": -540
    },
    "id": "eRwCELnWSjss"
   },
   "outputs": [],
   "source": [
    "# load configs and vocab\n",
    "\n",
    "ptr_config = Config(ptr_dir / 'config_char16424_ranked.json')\n",
    "data_config = Config(data_dir / 'config.json')\n",
    "model_config = Config('finetuning_config.json')\n",
    "with open(ptr_config.config, mode=\"r\") as io :\n",
    "    bert_config = json.loads(io.read())\n",
    "\n",
    "vocab = pickle.load(open(ptr_config.vocab, mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1661397073134,
     "user": {
      "displayName": "­전해주 / 학생 / 컴퓨터공학부",
      "userId": "05510950798256053380"
     },
     "user_tz": -540
    },
    "id": "8oJMVhhhUqUA",
    "outputId": "158f2126-4a18-4e9c-e452-80812c17c444"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CONVERT A STRING INTO CHAR]\n"
     ]
    }
   ],
   "source": [
    "# load preprocessor\n",
    "\n",
    "ptr_tokenizer = KBertRankedTokenizer(ptr_config.tokenizer, do_lower_case=False)\n",
    "pad_sequence = PadSequence(length=model_config.length, pad_val=vocab.to_indices(vocab.padding_token))\n",
    "preprocessor = PreProcessor(vocab=vocab, split_fn=ptr_tokenizer.tokenize, pad_fn=pad_sequence, subchar='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16524,
     "status": "ok",
     "timestamp": 1661397089657,
     "user": {
      "displayName": "­전해주 / 학생 / 컴퓨터공학부",
      "userId": "05510950798256053380"
     },
     "user_tz": -540
    },
    "id": "w9uo74uoUqq-",
    "outputId": "8d39d3fc-ed0b-4c88-f549-5341c3240d17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = BertConfig(**bert_config)\n",
    "model = SentenceClassifier(config, num_classes=model_config.num_classes, vocab=preprocessor.vocab)\n",
    "bert_pretrained = torch.load('checkpoints/best_snu_char16424_ranked.tar', map_location=torch.device('cpu'))\n",
    "model.load_state_dict(bert_pretrained['model_state_dict'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1661397301210,
     "user": {
      "displayName": "­전해주 / 학생 / 컴퓨터공학부",
      "userId": "05510950798256053380"
     },
     "user_tz": -540
    },
    "id": "3EjZDSTVvlXn",
    "outputId": "05f92336-f657-43b7-cb50-9d35f2027a61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_tokens:\n",
      "tensor([[    2,   693,  1598,  1499,   873,  4239,   192,   790,     5,     5,\n",
      "          2964,  6386,   419,     3,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    2, 13588,  1592,   708,   142,   367,     7,   254,    81,  1448,\n",
      "           745,  2117,     3,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,  4966,   180,  2858,    32,   743, 13840,   978,  2712,   254,\n",
      "             5,     5,  1185,   449, 12167,     9,   254,   161,    23,   551,\n",
      "          1158,    13,   488,  2006,   466,     3,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,   795,   254,  1401,    66,    79,     3,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1]])\n"
     ]
    }
   ],
   "source": [
    "txt_1 = '이런걸 왜 돈 주고 보냐.. 진짜 최악임'\n",
    "token_1 = torch.tensor(preprocessor.preprocess(txt_1)).view(1, -1)\n",
    "\n",
    "txt_2 = '짱 좋아 최고야 올해의 영화상 드립니다'\n",
    "token_2 = torch.tensor(preprocessor.preprocess(txt_2)).view(1, -1)\n",
    "\n",
    "txt_3 = '그냥 나쁘지 않은 킬링타임 영화.. 근데 굳이 영화관에서 볼 필요는 없는듯?'\n",
    "token_3 = torch.tensor(preprocessor.preprocess(txt_3)).view(1, -1)\n",
    "\n",
    "txt_4 = '감독은 영화 접어라'\n",
    "token_4 = torch.tensor(preprocessor.preprocess(txt_4)).view(1, -1)\n",
    "\n",
    "tokens = torch.cat((token_1, token_2, token_3, token_4), 0)\n",
    "print('test_tokens:')\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1601,
     "status": "ok",
     "timestamp": 1661397303338,
     "user": {
      "displayName": "­전해주 / 학생 / 컴퓨터공학부",
      "userId": "05510950798256053380"
     },
     "user_tz": -540
    },
    "id": "3bNPYwEbvlaA",
    "outputId": "4627c354-d1e2-4ff6-d324-e58122588e4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NEGATIVE', 'POSITIVE', 'POSITIVE', 'NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "output = model(tokens)\n",
    "print(['NEGATIVE' if o < 0.5 else 'POSITIVE' for o in output.max(dim=1)[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1661397623405,
     "user": {
      "displayName": "­전해주 / 학생 / 컴퓨터공학부",
      "userId": "05510950798256053380"
     },
     "user_tz": -540
    },
    "id": "t2zoENbaA3lv",
    "outputId": "146f07c1-ae0b-4cd8-f17b-dedfa4e2dec0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.8851, -2.8254],\n",
       "        [-2.2497,  2.4242],\n",
       "        [-1.7892,  1.9156],\n",
       "        [ 1.3974, -1.4130]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "KR-BERT-inference.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
